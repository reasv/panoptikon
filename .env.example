# This is an example .env file for Panoptikon.
# Don't modify it directly, as it will be overwritten when you update Panoptikon.
# Make a copy of this file, rename it to just ".env" then replace the values you want to change.
# Make sure to remove "#" from the beginning of a line if you intend to use that setting.
# Any lines starting with "#" are "comments" and will be ignored.

# The values set here are "environment variables" that are used by Panoptikon.
# If you want to temporarily override one or more of them for a specific run, you can do so by starting Panoptikon with:

# ENV_VAR=value ./panoptikon-start.sh

# on Linux, or

# set ENV_VAR=value
# panoptikon-start.bat

# on Windows, in the command line.
# Setting them in this file will make them permanent for all runs of Panoptikon.

# Change HOST and CLIENT_HOST to "0.0.0.0" if you want Panoptikon to be publicly accessible from other devices.
HOST=127.0.0.1
CLIENT_HOST=127.0.0.1

# The port the API server will run on.
# If you want to run multiple instances of Panoptikon on the same machine, they must have different ports.
PORT=6342
# The port the client will run on.
# This is the port you will access the web interface on, by default http://127.0.0.1:6339
CLIENT_PORT=6339

# Inferio port and host
# These only apply if you launch inferio separately from Panoptikon by running one of the inferio- start scripts.
INFERIO_HOST=127.0.0.1
INFERIO_PORT=7777

# The folder where index databases and where logs are stored by default.
# This is where the database files will be created. Make sure this folder exists and is writable.
DATA_FOLDER=data

# By default, Panoptikon will log to a file in the data folder.
# If you want to save the logs to a different file, set this to the path of the file.
#LOGS_FILE=data/panoptikon.log

# The log level of the server. Uncomment if you want more verbose console output.
#LOGLEVEL=DEBUG

# By default, Panoptikon will try to update the client automatically every time it starts.
# This is useful for development, but if you want to disable it, set this to true.
#DISABLE_CLIENT_UPDATE=false

# By default, Panoptikon launches the webui automatically when it starts.
# If you want to disable this, set this to true.
# For example, if you are running the web UI separately or don't need it. 
#ENABLE_CLIENT=true

# Where the client is running. Normally, not needed to be set.
#CLIENT_URL=http://127.0.0.1:6339/

# The list of (Nvidia) GPUs visible to Panoptikon.
# A single instance of Panoptikon or inferio can only use one GPU at a time,
# so you can choose it here. 
#CUDA_VISIBLE_DEVICES=0

# In the WebUI, when you click on "Show in File Manager" for a file,
# Panoptikon will try to open the file in the file manager with a 
# command suited to your OS.
# The following environment variable (SHOW_IN_FM_COMMAND) 
# allows you to override the default command, in order to customize it.
# You can include the following placeholders in the command:
# {path} - The full absolute path to the file
# {folder} - The directory the file is in
# {filename} - The name of the file within the directory
# These will be replaced with the actual values when the command is run.
# The replacements will be automatically surrounded by double quotes ("").
# For example, on Windows, you can set this to:
# SHOW_IN_FM_COMMAND=explorer.exe {folder}
# Which, for the file "C:\Users\user\Pictures\image.jpg" will be executed as:
# explorer.exe "C:\Users\user\Pictures"
# The following is the default command on Windows:
#SHOW_IN_FM_COMMAND=explorer /select, {path}

# Same as above, but for when you click on "Open File" in the WebUI,
# which will open the file in the default application for that file type.
# This can also be customized to any command you want, with the same placeholders.
# The following is the default setting on Linux:
#OPEN_FILE_COMMAND=xdg-open {path}

# Required when using the danbooru-saucenao tag matcher
#SAUCENAO_API_KEY=xxxx

# When using the Jina.ai API embedding service, at least JINA_API_KEY is required
#JINA_API_KEY=xxx
#JINA_MAX_RETRIES=3
#JINA_TIMEOUT=10

# If you're running the inference server (inferio) separately,
# you can point INFERENCE_API_URL to the URL of the inference server to allow Panoptikon to use it.
# By default, a Panoptikon instance will run its own inference server,
# which also means that you can point INFERENCE_API_URL to another Panoptikon instance to leverage its inference server.
# For example, you might have a full Panoptikon instance running on your desktop or workstation,
# and another instance running on your laptop without a GPU.
# You can point the laptop instance to the desktop instance's inference server to leverage the GPU.
#INFERENCE_API_URL=http://127.0.0.1:7777
# You can also point it to multiple inference servers, separated by commas:
#INFERENCE_API_URL=http://127.0.0.1:6342,http://127.0.0.1:7777,http://example.com:7777
# When specifying multiple URLs, Panoptikon will *distribute* the work across them.
# This allows you to use multiple GPUs on different machines, or even multiple GPUs on the same machine to
# speed up your jobs.
# If you want to use multiple GPUs on the same machine, you want to start an instance of inferio for each GPU,
# and for each instance, set CUDA_VISIBLE_DEVICES to the GPU you want to use, also assigning a different port to each instance.
# For example, if you have 4 GPUs, you can start 4 instances of inferio, each with a different port, by typing this on the command line (Linux):
# CUDA_VISIBLE_DEVICES=0 INFERIO_PORT=7777 ./inferio-start.sh
# CUDA_VISIBLE_DEVICES=1 INFERIO_PORT=7778 ./inferio-start.sh
# CUDA_VISIBLE_DEVICES=2 INFERIO_PORT=7779 ./inferio-start.sh
# CUDA_VISIBLE_DEVICES=3 INFERIO_PORT=7780 ./inferio-start.sh
# This will start 4 instances of inferio, each using a different GPU.
# Then, only on your Panoptikon instance, you can set INFERENCE_API_URL to:
#INFERENCE_API_URL=http://127.0.0.1:7777,http://127.0.0.1:7778,http://127.0.0.1:7779,http://127.0.0.1:7780
# This will allow Panoptikon to use all 4 GPUs at the same time.
# Note that Panoptikon starts an internal inferio instance on its own, so you could skip one of these,
# let's say the last one, set CUDA_VISIBLE_DEVICES=3 for the main Panoptikon instance (running on port 6342),
# and set
#INFERENCE_API_URL=http://127.0.0.1:6342,http://127.0.0.1:7777,http://127.0.0.1:7778,http://127.0.0.1:7779
# Note that although Panoptikon will start its own inferio instance, you still need to include it in the INFERENCE_API_URL list if set it at all.
# If INFERENCE_API_URL is not set, Panoptikon will use its own internal inferio instance by default.

# When using multiple inference servers (see previous setting), you can set the weights for each server here:
#INFERENCE_API_URL_WEIGHTS=1,1.5,2,1
# The order corresponds to the order within INFERENCE_API_URL. The values can be any positive float, but their number MUST match the number of URLs in INFERENCE_API_URL.
# The weights are used to determine how much work each server will get.
# For example, if you have 4 servers, and set the weights to 1, 1.5, 2, 1.5,
# The server with weight 2 will get twice as much work as the server with weight 1.
# This functions by splitting an individual batch into a batch for each server, with the size of the individual server batch being proportional to the weight.
# For this reason, giving a higher weight to a server will require it to have more VRAM available.
# For example, if you have 4 servers, with weights 1, 1.5, 2, 3.5, and you run a batch job with batch size 64,
# The first server will get 8 images from every batch (64 / (1 + 1.5 + 2 + 3.5) * 1 = 64 / 8 = 8), the second server will get 12, the third 16, and the last 28.

# By default, Panoptikon will try to download cudnn libraries automatically when it starts if they are not found.
# Set this to true if you want to disable this feature.
#NO_CUDNN=false

# Sometimes needed if you enable HTML document support on Windows.
# This is the path to the directory where the weasyprint DLLs are located.
# See https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#windows
#WEASYPRINT_DLL_DIRECTORIES=C:\msys64\mingw64\bin

# Folder used to store temporary files.
# This is video frames are stored while being extracted from videos.
#TEMP_DIR=./data/tmp